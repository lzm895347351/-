import tensorflow as tf
batch_size = 100
#初始化权值
def weight_va(shape):
    initial = tf.truncated_normal(shape,stddev=0.1)
    return tf.Variable(initial)
#初始化偏执值
def bias_va(shape):
    initial = tf.constant(0.1,shape=shape)
    return tf.Variable(initial)
#一步卷积操作
def conv2d_1(x,W):
    #x 输入的张量形状[批次，长，宽，通道数] 彩色图片通道数为3
    #W 滤波器张量[长，宽，输入通道数，输出通道数]
    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')
#两步卷积操作
def conv2d_2(x,W):
    #x 输入的张量形状[批次，长，宽，通道数] 彩色图片通道数为3 
    #W 滤波器张量[长，宽，输入通道数，输出通道数]
    return tf.nn.conv2d(x,W,strides=[1,2,2,1],padding='SAME')
#一步反卷积
def deconv2d_2(x,W,out):
    #x 输入的张量形状[批次，长，宽，通道数] 彩色图片通道数为3 
    #W 滤波器张量[长，宽，输入通道数，输出通道数]
    return tf.nn.conv2d_transpose(x,W,out,strides=[1,2,2,1],padding='SAME')
#两步反卷积
def deconv2d_1(x,W,out):
    #x 输入的张量形状[批次，长，宽，通道数] 彩色图片通道数为3 
    #W 滤波器张量[长，宽，输入通道数，输出通道数]
    return tf.nn.conv2d_transpose(x,W,out,strides=[1,1,1,1],padding='SAME')


#一步池化
def max_poll_2x2_1(x):
    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,1,1,1],padding='SAME')

#两步池化
def max_poll_2x2_2(x):
    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

source = tf.placeholder(tf.float32,[None,128,128,3])
target = tf.placeholder(tf.float32,[None,128,128,3])


#孪生子卷积网络
#第一层
W_conv1 = weight_va([3,3,3,16])
b_conv1 = bias_va([16])
sh_conv1 = tf.nn.relu(conv2d_1(source,W_conv1)+b_conv1)
th_conv1 = tf.nn.relu(conv2d_1(target,W_conv1)+b_conv1)


#第二层
W_conv2 = weight_va([3,3,16,32])
b_conv2 = bias_va([32])
sh_conv2 = tf.nn.relu(conv2d_2(sh_conv1,W_conv2)+b_conv2)
th_conv2 = tf.nn.relu(conv2d_2(th_conv1,W_conv2)+b_conv2)

#第三层
W_conv3 = weight_va([3,3,32,32])
b_conv3 = bias_va([32])
sh_conv3 = tf.nn.relu(conv2d_1(sh_conv2,W_conv3)+b_conv3)
th_conv3 = tf.nn.relu(conv2d_1(th_conv2,W_conv3)+b_conv3)

#第四层
W_conv4 = weight_va([3,3,32,64])
b_conv4 = bias_va([64])
sh_conv4 = tf.nn.relu(conv2d_2(sh_conv3,W_conv4)+b_conv4)
th_conv4 = tf.nn.relu(conv2d_2(th_conv3,W_conv4)+b_conv4)

#第五层
W_conv5 = weight_va([3,3,64,64])
b_conv5 = bias_va([64])
sh_conv5 = tf.nn.relu(conv2d_1(sh_conv4,W_conv5)+b_conv5)
th_conv5 = tf.nn.relu(conv2d_1(th_conv4,W_conv5)+b_conv5)

#第六层
W_conv6 = weight_va([3,3,64,128])
b_conv6 = bias_va([128])
sh_conv6 = tf.nn.relu(conv2d_2(sh_conv5,W_conv6)+b_conv6)
th_conv6 = tf.nn.relu(conv2d_2(th_conv5,W_conv6)+b_conv6)

#第七层
W_conv7 = weight_va([3,3,128,128])
b_conv7 = bias_va([128])
sh_conv7 = tf.nn.relu(conv2d_1(sh_conv6,W_conv7)+b_conv7)
th_conv7 = tf.nn.relu(conv2d_1(th_conv6,W_conv7)+b_conv7)

#第八层
W_conv8 = weight_va([3,3,128,256])
b_conv8 = bias_va([256])
sh_conv8 = tf.nn.relu(conv2d_2(sh_conv7,W_conv8)+b_conv8)
th_conv8 = tf.nn.relu(conv2d_2(th_conv7,W_conv8)+b_conv8)

#连接两输出
concat1 = tf.concat([th_conv8,sh_conv8],axis=3)

#flow解码器
fW = weight_va([3,3,512,512])
fb = bias_va([512])
fin = tf.nn.relu(conv2d_1(concat1,fW)+fb)


fW_deconv1 = weight_va([3,3,256,512])
fb_deconv1 = bias_va([256])
fh_deconv1 = tf.nn.relu(deconv2d_2(fin,fW_deconv1,[batch_size,16,16,256])+fb_deconv1)

fW_conv2 = weight_va([3,3,256,256])
fb_conv2 = bias_va([256])
fh_conv2 = tf.nn.relu(conv2d_1(fh_deconv1,fW_conv2)+fb_conv2)

fW_conv3 = weight_va([3,3,256,256])
fb_conv3 = bias_va([256])
fh_conv3 = conv2d_1(fh_conv2,fW_conv3)+fb_conv3

fW_deconv4 = weight_va([3,3,128,256])
fb_deconv4 = bias_va([128])
fh_deconv4 = tf.nn.relu(deconv2d_2(fh_conv3,fW_deconv4,[batch_size,32,32,128])+fb_deconv4)

fW_conv5 = weight_va([3,3,128,128])
fb_conv5 = bias_va([128])
fh_conv5 = tf.nn.relu(conv2d_1(fh_deconv4,fW_conv5)+fb_conv5)

fW_conv6 = weight_va([3,3,128,128])
fb_conv6 = bias_va([128])
fh_conv6 = conv2d_1(fh_conv5,fW_conv6)+fb_conv6

fW_deconv7 = weight_va([3,3,64,128])
fb_deconv7 = bias_va([64])
fh_deconv7 = tf.nn.relu(deconv2d_2(fh_conv6,fW_deconv7,[batch_size,32,32,64])+fb_deconv7)

fW_conv8 = weight_va([3,3,64,64])
fb_conv8 = bias_va([64])
fh_conv8 = tf.nn.relu(conv2d_1(fh_deconv7,fW_conv8)+fb_conv8)

fW_conv9 = weight_va([3,3,64,64])
fb_conv9 = bias_va([64])
fh_conv9 = conv2d_1(fh_conv8,fW_conv9)+fb_conv9

fW_deconv10 = weight_va([3,3,32,64])
fb_deconv10 = bias_va([32])
fh_deconv10 = tf.nn.relu(deconv2d_2(fh_conv9,fW_deconv10,[batch_size,128,128,32])+fb_deconv10)

fW_conv11 = weight_va([3,3,32,32])
fb_conv11 = bias_va([32])
fh_conv11 = tf.nn.relu(conv2d_1(fh_deconv10,fW_conv11)+fb_conv11)

fW_conv12 = weight_va([3,3,32,32])
fb_conv12 = bias_va([32])
fh_conv12 = conv2d_1(fh_conv11,fW_conv12)+fb_conv12

fW_deconv13 = weight_va([3,3,2,32])
fb_deconv13 = bias_va([2])
fh_deconv13 = tf.nn.relu(deconv2d_2(fh_conv12,fW_deconv13,[batch_size,128,128,2])+fb_deconv13) #！！！！

fW_conv14 = weight_va([3,3,2,2])
fb_conv14 = bias_va([2])
fh_conv14 = tf.nn.relu(conv2d_1(fh_deconv13,fW_conv14)+fb_conv14)

fW_conv15 = weight_va([3,3,2,2])
fb_conv15 = bias_va([2])
fh_conv15 = tf.nn.relu(conv2d_1(fh_conv14,fW_conv15)+fb_conv15)

fW_conv16 = weight_va([3,3,2,2])
fb_conv16 = bias_va([2])
flow_2d = tf.nn.relu(conv2d_1(fh_conv15,fW_conv16)+fb_conv16)

#match解码器
mW = weight_va([3,3,512,256])
mb = bias_va([256])
minp = tf.nn.relu(conv2d_1(concat1,mW)+mb)

mW_deconv1 = weight_va([3,3,128,256])
mb_deconv1 = bias_va([128])
mh_deconv1 = tf.nn.relu(deconv2d_2(minp,mW_deconv1,[batch_size,16,16,128])+mb_deconv1)

mW_conv2 = weight_va([3,3,128,128])
mb_conv2 = bias_va([128])
mh_conv2 = tf.nn.relu(conv2d_1(mh_deconv1,mW_conv2)+mb_conv2)

mW_conv3 = weight_va([3,3,128,128])
mb_conv3 = bias_va([128])
mh_conv3 = conv2d_1(mh_conv2,mW_conv3)+mb_conv3

mW_deconv4 = weight_va([3,3,64,128])
mb_deconv4 = bias_va([64])
mh_deconv4 = tf.nn.relu(deconv2d_2(mh_conv3,mW_deconv4,[batch_size,32,32,64])+mb_deconv4)

mW_conv5 = weight_va([3,3,64,64])
mb_conv5 = bias_va([64])
mh_conv5 = tf.nn.relu(conv2d_1(mh_deconv4,mW_conv5)+mb_conv5)

mW_conv6 = weight_va([3,3,64,64])
mb_conv6 = bias_va([64])
mh_conv6 = conv2d_1(mh_conv5,mW_conv6)+mb_conv6

mW_deconv7 = weight_va([3,3,32,64])
mb_deconv7 = bias_va([32])
mh_deconv7 = tf.nn.relu(deconv2d_2(mh_conv6,mW_deconv7,[batch_size,64,64,32])+mb_deconv7)

mW_conv8 = weight_va([3,3,32,32])
mb_conv8 = bias_va([32])
mh_conv8 = tf.nn.relu(conv2d_1(mh_deconv7,mW_conv8)+mb_conv8)

mW_conv9 = weight_va([3,3,32,32])
mb_conv9 = bias_va([32])
mh_conv9 = conv2d_1(mh_conv8,mW_conv9)+mb_conv9

mW_deconv10 = weight_va([3,3,16,32])
mb_deconv10 = bias_va([16])
mh_deconv10 = tf.nn.relu(deconv2d_2(mh_conv9,mW_deconv10,[batch_size,128,128,16])+mb_deconv10)

mW_conv11 = weight_va([3,3,16,16])
mb_conv11 = bias_va([16])
mh_conv11 = tf.nn.relu(conv2d_1(mh_deconv10,mW_conv11)+mb_conv11)

mW_conv12 = weight_va([3,3,16,16])
mb_conv12 = bias_va([16])
mh_conv12 = conv2d_1(mh_conv11,mW_conv12)+mb_conv12

mW_deconv13 = weight_va([3,3,2,16])
mb_deconv13 = bias_va([2])
mh_deconv13 = tf.nn.relu(deconv2d_2(mh_conv12,mW_deconv13,[batch_size,128,128,2])+mb_deconv13)

mW_conv14 = weight_va([3,3,2,2])
mb_conv14 = bias_va([2])
matchability = tf.nn.softmax(conv2d_1(mh_deconv13,mW_conv14)+mb_conv14)

thflow = tf.placeholder(tf.float32,[None,128,128,2])
thmatch = tf.placeholder(tf.float32,[None,128,128,2])
loss = tf.reduce_mean(thmatch * tf.square(flow_2d - thflow)) + 0.15 * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=thmatch,logits=matchability))
train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for epoch in range():
        for batch in range(n_batch):
            sess.run(train_step,feed_dict = {source:  , target:  ,thflow:  ,thmatch:  ,keep_prob:0.7})

